# FFT LLM Agent Configuration

[llm]
# Any OpenAI-compatible endpoint (LM Studio, Ollama, Gemini, GLM, OpenRouter, etc.)
# Set api_key via environment variable (OPENAI_API_KEY) or leave blank for local endpoints
base_url = "http://10.0.1.46:1234/v1"
model = "zai-org/glm-4.6v-flash"
# api_key = ""  # Optional: set in env var or uncomment and fill here

# Thinking/Reasoning models need lower temp for precision, higher timeout for thought generation
temperature = 0.4
max_tokens = 100000
timeout = 120.0

[game]
# Difficulty: 
# - easy / squire (no level scaling)
# - normal / knight (standard scaling)
# - hard / tactician (aggressive scaling, smarter AI)
difficulty = "tactician"

# Auto-save settings
auto_save = true
save_interval = 5  # Save every N battles

[timing]
# Seconds between actions
action_delay = 0.2
# Minimum think time per decision
think_time = 1.0
# Cutscene skip delay
cutscene_delay = 0.3

[capture]
window_title = "Eden"  # Target window name (partial match)

[debug]
verbose = true
log_prompts = true
save_screenshots = false
screenshot_dir = "./screenshots"

[gdb]
# GDB stub for memory reading (game state)
enabled = true
host = "127.0.0.1"
port = 6543

[strategy]
# Enable learning from battle outcomes (recommended)
learning_enabled = true
# Enable power-ups/cheats (set to false for pure LLM training)
cheats_enabled = false
# Max power-ups per battle (if cheats enabled)
max_powerups_per_battle = 3

[cemuhook]
host = "127.0.0.1"
port = 26760

[ocr]
# OCR engine: tesseract, easyocr, none (mock)
engine = "tesseract"
# UI regions (calibrate for your screen resolution)
# Format: x, y, width, height

[ocr.regions]
unit_stats = [900, 100, 300, 200]
battle_log = [100, 500, 600, 100]
menu = [400, 300, 400, 300]
